# -*- coding: utf-8 -*-
"""testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n78vbjDiRLV7wtuup77B1xsq4egjEI_h
"""

import numpy as np
import pandas as pd
import tensorflow as tf

from datetime import datetime
from tensorflow import keras
from tensorflow.keras import layers

import warnings
warnings.filterwarnings("ignore")

print(tf.version.VERSION)
print(keras.__version__)

from google.colab import files
util = files.upload()
transformed_model_data = files.upload()
transformed_test_data = files.upload()

from util import *

df = pd.read_csv("transformed_model_data_t1.csv")
df_test = pd.read_csv("transformed_test_data_t1.csv")

def get_metrics(y_pred, val_set, k=20):
    hitt, pret, ndct = 0, 0, 0
    c_list = val_set["c_ids"]
    counter = len(c_list)
    for i in range(counter):
        rel = val_set["target"][i][-1]
        ret = y_pred[i][-1].argsort()[::-1][:k]
        bl = np.isin(ret, rel)*1
        pre = average_precision(bl)
        ndc = ndcg_k(bl, len(bl))
        h = np.max(bl)
        hitt += h
        pret += pre
        ndct += ndc
    return hitt/counter, pret/counter, ndct/counter

exp_df = pd.DataFrame(columns=["model", "n_time", "emb_unit",
                               "rnn_unit", "drop_rate",
                               "learning", "acc", 
                               "loss", "hit", "map",
                               "ndcg", "repl", "epoch",
                               "n_train_c", "n_test_c"])

pro_max = df["item_id"].astype("int64").max()
rec_max = df["recency"].astype("int64").max()
pay_max = df["payment"].astype("int64").max()
cat_max = df["category"].astype("int64").max()
mon_max = df["month"].astype("int64").max()
day_max = df["dayofweek"].astype("int64").max()
pri_max = df["price"].astype("int64").max()
sin_max = df["c_since"].astype("int64").max()
cust_base = df["c_id"].unique()

BATCH_SIZE = 256
N_TIME = [12]
MODEL_NUM = [3]
N_EPOCH = 50
EMB = 256
RNN = 400

for n in N_TIME:
    train_set = make_data_dict(df, n)
    test_set = make_data_dict(df_test, n)
    train_set_ = create_batch_data(train_set, batch=BATCH_SIZE)
    test_set_ = create_batch_data(test_set, batch=BATCH_SIZE)
    for m in MODEL_NUM:
        hparams = {
            "bidirect": False,
            "style": "lstm",
            "model": m,
            "emb_unit": EMB,
            "rnn_unit": RNN,
            "dropout": 0.8,
            "learning": 0.0001,
            "n_time": n,
            "item_max": pro_max,
            "price_max": pri_max,
            "recency_max": rec_max,
            "payment_max": pay_max,
            "category_max": cat_max,
            "month_max": mon_max,
            "dayofweek_max": day_max,
            "since_max": sin_max,
        }
        model = model_base(hparams)
        for ep in range(N_EPOCH):
            hist = model.fit(train_set_, epochs=1, verbose=0)
            acc = hist.history["sparse_categorical_accuracy"][-1]
            loss = hist.history["loss"][-1]
            y_pred = hist.model.predict(test_set_)
            hit, pre, ndcg = get_metrics(y_pred, test_set)
            exp_df = exp_df.append({"model": m,
                                    "n_time": n,
                                    "emb_unit": EMB,
                                    "rnn_unit": RNN,
                                    "drop_rate": 0.8,
                                    "learning": 0.0001,
                                    "acc": acc,
                                    "loss": loss,
                                    "hit": hit,
                                    "map": pre,
                                    "ndcg": ndcg,
                                    "epoch": ep}, ignore_index=True)
            print(ep, hit, pre, ndcg)
        del model, hist, y_pred

file = "".join(np.random.choice(["a", "b", "c", "d", "e", 0, 1, 2, 3, 4], 4))
exp_df.to_csv("results_test_" + file + ".csv", sep=";", index=False)
files.download("results_test_" + file + ".csv")