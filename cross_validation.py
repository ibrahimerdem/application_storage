# -*- coding: utf-8 -*-
"""cross_validation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tJ1I-jeG-CmMQKp6zUpihTnR3vS5ymYn
"""

import numpy as np
import pandas as pd
import tensorflow as tf

from datetime import datetime
from tensorflow import keras
from tensorflow.keras import layers

import warnings
warnings.filterwarnings("ignore")

print(tf.version.VERSION)
print(keras.__version__)

from google.colab import files
util = files.upload()
transformed_model_data = files.upload()

from util import *

df = pd.read_csv("transformed_model_data_t1.csv")

def get_metrics(y_pred, val_set, k=20):
    hitt, pret, ndct = 0, 0, 0
    c_list = val_set["c_ids"]
    counter = len(c_list)
    for i in range(counter):
        rel = val_set["target"][i][-1]
        ret = y_pred[i][-1].argsort()[::-1][:k]
        bl = np.isin(ret, rel)*1
        pre = average_precision(bl)
        ndc = ndcg_k(bl, len(bl))
        h = np.max(bl)
        hitt += h
        pret += pre
        ndct += ndc
    return hitt/counter, pret/counter, ndct/counter

exp_df = pd.DataFrame(columns=["model", "n_time", "emb_unit",
                               "rnn_unit", "drop_rate",
                               "learning", "acc", 
                               "loss", "hit", "map",
                               "ndcg", "repl", "n_epoch",
                               "n_train_c", "n_val_c"])

pro_max = df["item_id"].astype("int64").max()
rec_max = df["recency"].astype("int64").max()
pay_max = df["payment"].astype("int64").max()
cat_max = df["category"].astype("int64").max()
mon_max = df["month"].astype("int64").max()
day_max = df["dayofweek"].astype("int64").max()
pri_max = df["price"].astype("int64").max()
sin_max = df["c_since"].astype("int64").max()
cust_base = df["c_id"].unique()

TRAIN_SIZE = 0.8
BATCH_SIZE = 256
N_VAL = 5
N_TIME = [12]
MODEL_NUM = [4]
EMB_UNITS = [1024]
RNN_UNITS = [400, 600]
DROP_RATE = [0.8]
L_RATE = [0.0001]

run = 0
for n in N_TIME:
    for v in range(N_VAL):
        random_selection = np.random.rand(len(cust_base)) <= TRAIN_SIZE
        val_cust = cust_base[~random_selection]
        val_data = df[df["c_id"].isin(val_cust)]
        train_data = df[~(df["c_id"].isin(val_cust))]
        train_set = make_data_dict(train_data, n)
        val_set = make_data_dict(val_data, n)
        train_set_ = create_batch_data(train_set, batch=BATCH_SIZE)
        val_set_ = create_batch_data(val_set, batch=BATCH_SIZE)
        del train_data, val_data
        for m in MODEL_NUM:
            for e in EMB_UNITS:
                for r in RNN_UNITS:
                    for d in DROP_RATE:
                        for l in L_RATE:
                                hparams = {
                                    "bidirect": False,
                                    "style": "lstm",
                                    "model": m,
                                    "emb_unit": e,
                                    "rnn_unit": r,
                                    "dropout": d,
                                    "learning": l,
                                    "n_time": n,
                                    "item_max": pro_max,
                                    "price_max": pri_max,
                                    "recency_max": rec_max,
                                    "payment_max": pay_max,
                                    "category_max": cat_max,
                                    "month_max": mon_max,
                                    "dayofweek_max": day_max,
                                    "since_max": sin_max,
                                    "replication": v
                                }
                                model = model_base(hparams)
                                hist = model_training(model, train_set_, val_set_)
                                acc = hist.history["val_sparse_categorical_accuracy"][-1]
                                loss = hist.history["val_loss"][-1]
                                y_pred = hist.model.predict(val_set_)
                                hit, pre, ndcg = get_metrics(y_pred, val_set)
                                n_tr = len(train_set["c_ids"])
                                n_val = len(val_set["c_ids"])
                                epo = hist.epoch[-1]+1
                                exp_df = exp_df.append({"model": m,
                                                        "n_time": n,
                                                        "emb_unit": e,
                                                        "rnn_unit": r,
                                                        "drop_rate": d,
                                                        "learning": l,
                                                        "acc": acc,
                                                        "loss": loss,
                                                        "hit": hit,
                                                        "map": pre,
                                                        "ndcg": ndcg,
                                                        "repl": v+1,
                                                        "n_epoch": epo,
                                                        "n_train_c": n_tr,
                                                        "n_val_c": n_val}, ignore_index=True)
                                print(run)
                                run += 1
                                del model, hist, y_pred

file = "".join(np.random.choice(["a", "b", "c", "d", "e", 0, 1, 2, 3, 4], 4))
exp_df.to_csv("results_" + file + ".csv", sep=";", index=False)
files.download("results_" + file + ".csv")